<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>scrapy使用笔记 | 数列卡索的魔法小屋</title>
  <meta name="generator" content="Jekyll" />
  <meta name="author" content="amyangfei" />
  <meta name="description" content="介绍使用scrapy爬虫框架中遇到的一个问题和解决方法 " />
  <meta name="keywords" content="scrapy, python, crawler, yield " />
  <link rel="stylesheet" href="/css/style.css" type="text/css" />
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
</head>
<body>
    <header class="head">
	<div class="header fn-clear">
		<section class="header-cnt fn-clear">
			<div class="logo">
				<div class="logo-cnt">
				 	<h1><a href="/">Amyangfei</a></h1>
				 	<h2>Study, Geek & Share</h2>
				</div>
			</div>
			<nav class="nav">
				<ul>
					<li><a href="/" >Home</a></li>
					<li><a href="/archives.html" >Archives</a></li>
					<li><a href="/contact.html" >About & Contact</a></li>
					<li><a href="/atom.xml" target="_blank" >Rss</a></li>
				</ul>
			</nav>
		</section>
	</div>
</header> 
  <section id="content">
    <article id="contenter">
      <section class="content">

	<div class="content-cnt fn-clear">

		<div class="v-section-tit fn-clear">
	        <a href="/" rel="nofollow" >Home</a>
	        <span>&#9830;</span>
	        <a href="/archives.html" rel="nofollow" >Archives</a>
	        <span>&#9830;</span>
	        <h2>scrapy使用笔记</h2>
    	</div>

		<div class="main fn-clear">
			<article class="entry">
				<h1 class="title">scrapy使用笔记</h1>
               	<p class="meta"><time class="date" pubdate="2013-03-16">16 Mar 2013</time> By <a href="/contact.html" class="author" title="author">amyangfei</a><g:plusone size="small"></g:plusone></p>
               	<p class="description">介绍使用scrapy爬虫框架中遇到的一个问题和解决方法</p>
 			 	<p>最近在使用 scrapy 做爬虫，整个爬取框架很清晰，使用 <a href="http://twistedmatrix.com/trac/" target="_blank">twisted</a> 这个异步网络库来处理网络通讯，由 scrapy engine 作为系统调度。具体使用时通过继承 BaseSpider 自定义爬虫类，用户自己实现具体的页面分析、提供带抓取url，系统会自动调度完成页面的请求、下载返回resonse供解析。对于需要保存的数据，可以送到 Item Pipeline 中做后续处理。</p>

<h3>递归爬取页面</h3>

<p>爬虫运行时不断发现新的页面并进行爬取。跟踪 scrapy 源码中 BaseSpider 类，会发现下边的方法。爬去框架初始运行时会由系统调度，通过调用 next()，在 yield 挂起处继续执行 make_requests_from_url 返回 Request 对象，然后由系统调度进一步请求页面。每次爬去页面返回获得response后执行 spider 中的 parse 函数。</p>

<div class="highlight"><pre><code class="python"><span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span><span class="p">:</span>
        <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_requests_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_requests_from_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">dont_filter</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c">#code in engine.py/class ExecutionEngine</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">request</span> <span class="o">=</span> <span class="n">slot</span><span class="o">.</span><span class="n">start_requests</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
    <span class="n">slot</span><span class="o">.</span><span class="n">start_requests</span> <span class="o">=</span> <span class="bp">None</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">exc</span><span class="p">:</span>
    <span class="n">log</span><span class="o">.</span><span class="n">err</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="s">&#39;Obtaining request from start requests&#39;</span><span class="p">,</span> <span class="n">spider</span><span class="o">=</span><span class="n">spider</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="n">spider</span><span class="p">)</span>
</code></pre></div>


<p>爬虫爬取时会不断发现新的 url 要爬取，在scrapy中实现递归爬取的方法很简单，只需要将下面的代码加到 parse 函数中。这样 parse 会在 yield 处挂起，等待系统的调度。下一次调用 next()后返回挂起点继续执行。</p>

<div class="highlight"><pre><code class="python"><span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_requests_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="c"># you can also use the following line</span>
<span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">make_requests_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</code></pre></div>


<p>需要注意的是递归调用 make_requests_from_url 的代码 <b>一定写在 parse 函数中</b>，否则如果像下边代码的结构，parse 调用 _handle_page ，当_handle_page 进入 yield 语句块时会挂起，等待 next 信号，但是 parse 函数会运行退出，于是 yield 后的 make_requests_from_url 将不再会被调用，爬取也无法递归的进行下去。我一开始写就遇到了这个问题，分析系统调度过程中使用 yield 之后发现了问题所在。</p>

<div class="highlight"><pre><code class="python"><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="n">page_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gen_type_fromurl</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>       
    <span class="bp">self</span><span class="o">.</span><span class="n">_handle_page</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">page_type</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_handle_page</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">page_type</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">page_type</span> <span class="o">==</span> <span class="s">&#39;subject&#39;</span><span class="p">:</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">new_url</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;rr&quot;]/a/@href&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_requests_from_url</span><span class="p">(</span><span class="n">new_url</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">page_type</span> <span class="o">==</span> <span class="s">&#39;review&#39;</span><span class="p">:</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@id=&quot;link-report&quot;]/div&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</code></pre></div>


<p>下边这个 demo 是上边错误的简化版本，调用 funcb 函数，funcc 函数挂起，funcb 内部的代码执行后 funcb 函数退出。</p>

<div class="highlight"><pre><code class="python"><span class="k">def</span> <span class="nf">funcb</span><span class="p">():</span>
    <span class="k">print</span> <span class="s">&#39;fun-b starts&#39;</span>
    <span class="n">funcc</span><span class="p">()</span>
    <span class="k">print</span> <span class="s">&#39;fun-b ends&#39;</span>

<span class="k">def</span> <span class="nf">funcc</span><span class="p">():</span>
    <span class="k">print</span> <span class="s">&#39;fun-c starts&#39;</span>
    <span class="k">yield</span> <span class="s">&#39;fun-c yield&#39;</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">funcb</span><span class="p">()</span>

<span class="c">#output</span>
<span class="n">fun</span><span class="o">-</span><span class="n">b</span> <span class="n">starts</span>
<span class="n">fun</span><span class="o">-</span><span class="n">b</span> <span class="n">ends</span>    
</code></pre></div>


<h3>Scrapy相关资源链接</h3>

<ol>
<li><a href="http://blog.pluskid.org/?p=366" target="_blank">Scrapy 轻松定制网络爬虫</a></li>
<li><a href="http://www.yakergong.net/blog/archives/500" target="_blank">使用scrapy进行大规模抓取</a></li>
<li><a href="http://isbullsh.it/2012/04/Web-crawling-with-scrapy/" target="_blank">Crawl a website with scrapy</a></li>
</ol>


                <nav class="pagination-link">
                    
                    <a class="prev" href="/2013/03/01/tornado-source-analysis-5/" rel="bookmark">&laquo;&nbsp;tornado源码分析5</a>
                    
                    
                    <a class="next" href="/2013/05/05/stl-heap-llvm-gcc/" rel="bookmark">stl make_heap在llvm和g++下的不同实现&nbsp;&raquo;</a>
                    
                 </nav>
			</article><!-- .entry -->
			<div class="violet-comment">
	             <div id="disqus_thread"></div>
	        </div><!-- //violet-comment -->
		</div>
		<div class="aside fn-clear">
			<div class="box fn-clear">
        <h3 class="title">Recent Posts</h3>
        <ul>
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/05/05/stl-heap-llvm-gcc/" title="stl make_heap在llvm和g++下的不同实现" rel="bookmark">stl make_heap在llvm和g++下的不同实现</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/03/16/tips-of-scrapy/" title="scrapy使用笔记" rel="bookmark">scrapy使用笔记</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/03/01/tornado-source-analysis-5/" title="tornado源码分析5" rel="bookmark">tornado源码分析5</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/02/28/access-vm-ssh-via-port-mapping/" title="通过端口映射访问虚拟机内部网络" rel="bookmark">通过端口映射访问虚拟机内部网络</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/02/08/android-taskscheduler-and-scripting/" title="Android运行脚本与定时工具" rel="bookmark">Android运行脚本与定时工具</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/02/05/tornado-source-analysis-4/" title="tornado源码分析4" rel="bookmark">tornado源码分析4</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/02/03/tornado-source-analysis-3/" title="tornado源码分析3" rel="bookmark">tornado源码分析3</a>
                </li>                                       
           
                <li class="v-aside-li">
                        <span class="v-span">&#8227;</span><a href="/2013/01/29/tornado-source-analysis-2/" title="tornado源码分析2" rel="bookmark">tornado源码分析2</a>
                </li>                                       
        
        </ul>  
</div>
		</div>
	</div>
</section>
    </article>
  </section>
    <footer class="foot">
	<div class="foot-cnt fn-clear">
		<div class="foot-cnt-det fn-clear">
			
			<article class="blogroll">
				<h4 class="title">QR code</h4>
				<ul>
					<img src="/images/static/qrcode.png"></img>
				</ul>
			</article>
			<article class="about">
				<h4 class="title">About Me</h4>
				<p>I am 数列卡索.<br> A coder and dream runner.<br> Life is ephemeral while working is endless.<br> No pain, no gain</p>
			</article>
			<article class="follow">
				<h4 class="title">Follow Me</h4>
				<ul>
					<li><a href="https://github.com/amyangfei" class="ico-github" target="_blank">github</a></li>
					<li><a href="/atom.xml" class="ico-rss" target="_blank">rss</a></li>
					<li><a href="https://www.twitter.com/amyangfei" class="ico-twitter" target="_blank">twitter</a></li>
					<li><a href="https://www.facebook.com/amyangfei" class="ico-facebook" target="_blank">facebook</a></li>
					<li><a href="http://weibo.com/amyangfei" class="ico-weibo" target="_blank">weibo</a></li>
					<li><a href="http://www.douban.com/people/amyangfei" class="ico-douban" target="_blank">douban</a></li>
				</ul>
			</article>
		</div>
	</div>
	<div class="foot-btn">
		<div class="foot-btn-det">
			<p class="copyright">Copyright © 2012 amyangfei All rights reserved.</p>&nbsp&nbsp
			<span class="v-tj">
				<script src="http://s22.cnzz.com/stat.php?id=3939200&web_id=3939200&show=pic" language="JavaScript">	
				</script>
			</span>
			<p class="author">Powered by <a href="http://www.jekyllrb.com" target="_blank">Jekyll</a> and <a href="http://www.pizn.net" target="_blank">PIZn</a>.</p>
		</div>
	</div>
</footer>

    
    <script type="text/javascript">
        
        //disqus
        var disqus_shortname = 'amyangfei';
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] ||
                document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    

    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-30252000-1']);
        _gaq.push(['_trackPageview']);
        (function() {
          var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
              ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
          var s = document.getElementsByTagName('script')[0];
              s.parentNode.insertBefore(ga, s);
        })();
    </script>
</body>
</html>
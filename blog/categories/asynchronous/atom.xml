<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Asynchronous | Amyangfei's Blog]]></title>
  <link href="http://amyangfei.me/blog/categories/asynchronous/atom.xml" rel="self"/>
  <link href="http://amyangfei.me/"/>
  <updated>2014-04-05T21:40:04+08:00</updated>
  <id>http://amyangfei.me/</id>
  <author>
    <name><![CDATA[amyangfei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用Tornado进行异步编程]]></title>
    <link href="http://amyangfei.me/2013/06/17/asynchronous-programming-with-tornado/"/>
    <updated>2013-06-17T00:00:00+08:00</updated>
    <id>http://amyangfei.me/2013/06/17/asynchronous-programming-with-tornado</id>
    <content type="html"><![CDATA[<p>翻译自：<a href="http://lbolla.info/blog/2012/10/03/asynchronous-programming-with-tornado" target="_blank">Asynchronous programming with Tornado</a></p>

<p>对于初学者来说异步编程很令人迷惑，因此我觉得有必要介绍一些有用的基本概念来帮助初学者避免一些常见的陷阱。如果希望理解通用的异步编程模型，可以查看以下这些网络资源，<a href="http://cs.brown.edu/courses/cs196-5/f12/handouts/async.pdf" target="_blank">Introduction to Asynchronous Programming</a>，<a href="http://krondo.com/?page_id=1327" target="_blank">Twisted Introduction</a>。在这篇文章中我将会着眼于如何使用 Tornado 进行异步编程。</p>

<p>来自Tornado主页的一段话：</p>

<blockquote><p>FriendFeed&rsquo;s web server is a relatively simple, non-blocking web server written in Python. The FriendFeed application is written using a web framework that looks a bit like web.py or Google&rsquo;s webapp, but with additional tools and optimizations to take advantage of the non-blocking web server and tools. Tornado is an open source version of this web server and some of the tools we use most often at FriendFeed. The framework is distinct from most mainstream web server frameworks (and certainly most Python frameworks) because it is non-blocking and reasonably fast. Because it is non-blocking and uses epoll or kqueue, it can handle thousands of simultaneous standing connections, which means the framework is ideal for real-time web services. We built the web server specifically to handle FriendFeed&rsquo;s real-time features every active user of FriendFeed maintains an open connection to the FriendFeed servers. (For more information on scaling servers to support thousands of clients, see The C10K problem.)</p></blockquote>

<p>对于初学者首先需要认清的是自己是否真的需要异步操作。异步编程比同步编程复杂得多，因此有人说：异步编程是不适合人类大脑的。</p>

<!-- more -->


<p>如果你的应用需要监控一些资源并且当这些资源的状态发生变化时需要采取一定的操作，那么你需要使用异步编程。比如对于一个 web 服务器，如果没有请求到达，那么它处于空闲状态；当有请求通过 socket 到达 web 服务器它就需要对这条请求进行一定的处理。另外一种需要异步编程的情况比如一个应用需要定期的执行一些任务或者延迟一段时间再执行代码。可以使用多线程/进程来控制多个任务的并发执行，那样编程模型也会迅速变得复杂起来。</p>

<p>第二步是需要确认你想要的操作是否能够进行异步操作。不幸的是在 Tornado 中，并非所有的功能都可以异步执行。</p>

<p>Tornado是单线程运行的（尽管在实际应用中，它支持多线程模式），因此阻塞操作会阻塞整个服务器。这意味着一个阻塞操作将会阻止系统执行下一个等待执行的任务。任务的调度通过<a href="http://www.tornadoweb.org/en/stable/ioloop.html" target="_blank"> IOLoop </a>完成，IOLoop运行在唯一的可用的线程中。</p>

<p>下边是一个错误使用 IOLoop 的例子（译者注：这段代码与原文不一样，是按照原文的描述修改的）：</p>

<p>``` python
import time
from tornado.ioloop import IOLoop
from tornado import gen</p>

<p>@gen.engine
def f():</p>

<pre><code>print 'sleeping'
time.sleep(1)
print 'awake!'
</code></pre>

<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:</p>

<pre><code># Note that now code is executed "concurrently"
IOLoop.instance().add_callback(f)
IOLoop.instance().add_callback(f)
IOLoop.instance().start()
</code></pre>

<p>```</p>

<p>注意到 blocking_call（译者注：函数f，不知道为什么原文作者说这是blocking_call） 被正确地调用，但是由于它被 time.sleep 阻塞，会阻止接下来任务（第二次调用该函数）的执行。只有当第一次调用结束后，这个函数才会被IOLoop 调度第二次调用。因此输出是这样的一个序列（“sleeping”, “awake!”, “sleeping”, “awake!”）。</p>

<p>对比同样的代码，但是使用 time.sleep 的异步版本，例如 add_timeout：</p>

<p>``` python</p>

<h1>Example of non-blocking sleep.</h1>

<p>import time
from tornado.ioloop import IOLoop
from tornado import gen</p>

<p>@gen.engine
def f():</p>

<pre><code>print 'sleeping'
yield gen.Task(IOLoop.instance().add_timeout, time.time() + 1)
print 'awake!'
</code></pre>

<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:</p>

<pre><code># Note that now code is executed "concurrently"
IOLoop.instance().add_callback(f)
IOLoop.instance().add_callback(f)
IOLoop.instance().start()
</code></pre>

<p>```</p>

<p>在这种情况下，函数 f 第一次被调用，会打印“sleeping”，然后它会在1秒之后向 IOLoop 请求继续执行。IOLoop 重获控制权，它会调度函数 f 的第二次调用，第二次调用首先打印“sleeping”，之后将控制权还给 IOLoop。1秒钟后 IOLoop 会在第一个函数挂起的位置继续执行并且打印“awake”。最后，第二次“awake”也会被打印。所以全部的打印序列为“sleeping”, “sleeping”, “awake!”, “awake!”。这两次函数调用是并发执行的（但不是<a href="http://stackoverflow.com/questions/1897993/difference-between-concurrent-programming-and-parallel-programming" target="_blank">并行</a>！）</p>

<p>现在我会听到你提问：“我如何创建一个函数并且异步地执行它？”在 Tornado 中，每一个有“callback”参数的函数都可以使用 “gen.engine.Task（译者注：应该是gen.Task）”进行异步操作。但是要注意：使用 Task 并不意味着就一定是异步执行！一个事实是函数会被调度获得控制权并执行，执行后任何传递给 callback 的值都会在 Task 中返回。看下边的代码：</p>

<p>``` python
import time
from tornado.ioloop import IOLoop
from tornado import gen</p>

<p>def my_function(callback):</p>

<pre><code>print 'do some work'
# Note: this line will block!
time.sleep(1)
callback(123)
</code></pre>

<p>@gen.engine
def f():</p>

<pre><code>print 'start'
# Call my_function and return here as soon as "callback" is called.
# "result" is whatever argument was passed to "callback" in "my_function".
result = yield gen.Task(my_function)
print 'result is', result
IOLoop.instance().stop()
</code></pre>

<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:</p>

<pre><code>f()
IOLoop.instance().start()
</code></pre>

<p>```</p>

<p>绝大多数初学者可能会这样写：Task(my_func)，然后认为 my_func 会自动被异步执行。事实上这并不是 Tornado 工作的原理，这是<a href="http://golang.org/" target="_blank"> Go </a>如何工作的！下边是我最后的建议(译者注：我觉得这是这篇文章最重要的建议)：</p>

<blockquote><p><strong><em> In a function that is going to be used “asynchronously”, only asynchronous libraries should be used. </em></strong></p></blockquote>

<p>就是说如果希望异步编程，那么一些阻塞的调用比如 time.sleep 或者 urllib2.urlopen 或者 db.query，它们需要替换成相应的异步版本。比如，IOLoop.add_timeout 是 time.sleep 的替换，AsyncHTTPClient.fetch 是 urllib2.urlopen 的替换等等。对于数据库查询，情况比较复杂，需要一些特定的异步查询驱动，比如对于 MongoDB 的<a href="http://blog.mongodb.org/post/30927719826/motor-asynchronous-driver-for-mongodb-and-python" target="_blank"> Motor </a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tornado源码分析5]]></title>
    <link href="http://amyangfei.me/2013/03/01/tornado-source-analysis-5/"/>
    <updated>2013-03-01T00:00:00+08:00</updated>
    <id>http://amyangfei.me/2013/03/01/tornado-source-analysis-5</id>
    <content type="html"><![CDATA[<p>Tornado的web框架在web.py中实现，主要包括RequestHandler类（本质为对http请求处理的封装）和Application类（是一些列请求处理的集合，构成的一个web-application，源代码注释不翻译更容易理解：A collection of request handlers that make up a web application）。</p>

<h3>RequestHandler分析</h3>

<p>RequestHandler提供了一个针对http请求处理的基类封装，方法比较多，主要有以下功能：</p>

<ol>
<li><p>提供了GET/HEAD/POST/DELETE/PATCH/PUT/OPTIONS等方法的功能接口，具体开发时RequestHandler的子类重写这些方法以支持不同需求的请求处理。</p></li>
<li><p>提供对http请求的处理方法，包括对headers，页面元素，cookie的处理。</p></li>
<li><p>提供对请求响应的一些列功能，包括redirect，write（将数据写入输出缓冲区），渲染模板（render, reander_string）等</p></li>
<li><p>其他的一些辅助功能，如结束请求/响应，刷新输出缓冲区，对用户授权相关处理等。</p></li>
</ol>


<!-- more -->


<h3>Application分析</h3>

<p>源代码中的注释写的非常好：A collection of request handlers that make up a web application. Instances of this class are <strong>callable</strong> and can be passed directly to HTTPServer to serve the application. 该类初始化的第一个参数接受一个(regexp, request_class)形式的列表，指定了针对不同URL请求所采取的处理方法，包括对静态文件请求的处理（web.StaticFileHandler）。Application类中实现 <a href="http://docs.python.org/2/reference/datamodel.html#object.__call__" target="_blank">__call__</a> 函数，这样该类就成为可调用的对象，由HTTPServer来进行调用。比如下边是httpserver.py中HTTPConection类的代码，该处request_callback即为Application对象。</p>

<p>``` python</p>

<p>def _on_headers(self, data):</p>

<pre><code># some codes...
self.request_callback(self._request)
</code></pre>

<p>```</p>

<p>__call__函数会遍历Application的handlers列表，匹配到相应的URL后通过handler._execute进行相应处理；如果没有匹配的URL，则会调用ErrorHandler。</p>

<p>在Application初始时有一个debug参数，当debug=True时，运行程序时当有代码、模块发生修改，程序会自动重新加载，即实现了auto-reload功能。该功能在autoreload.py文件中实现，是否需要reload的检查在每次接收到http请求时进行，基本原理是检查每一个sys.modules以及_watched_files所包含的模块在程序中所保存的最近修改时间和文件系统中的最近修改时间是否一致，如果不一致，则整个程序重新加载。</p>

<p>``` python
def _reload_on_update(modify_times):</p>

<pre><code>for module in sys.modules.values():
    # module test and some path handles
    _check_file(modify_times, path)
for path in _watched_files:
    _check_file(modify_times, path)
</code></pre>

<p>```</p>

<p>Tornado的autoreload模块提供了一个对外的main接口，可以通过下边的方法实现运行test.py程序运行的auto-reload。但是测试了一下，功能有限，相比于django的autorelaod模块（具有较好的封装和较完善的功能）还是有一定的差距。最主要的原因是Tornado中的实现耦合了一些ioloop的功能，因而autoreload不是一个可独立的模块。</p>

<p>``` bash</p>

<h1>tornado</h1>

<p>python -m tornado.autoreload test.py [args&hellip;]</p>

<h1>django</h1>

<p>from django.utils import autoreload
autoreload.main(your-main-func)
```</p>

<h3>asynchronous方法</h3>

<p>该方法通常被用为请求处理函数的decorator，以实现异步操作，被@asynchronous修饰后的请求处理为长连接，在调用self.finish之前会一直处于连接等待状态。</p>

<h3>总结</h3>

<p><a href="http://amyangfei.me/2013/01/29/tornado-source-analysis-2/" target="_blank">tornado源码分析2</a> 一文中给出了一张tornado httpserver的工作流程图，调用Application发生在HTTPConnection大方框的handle_request椭圆中。那篇文章里使用的是一个简单的请求处理函数handle_request，无论是handle_request还是application，其本质是一个函数（可调用的对象），当服务器接收连接并读取http请求header之后进行调用，进行请求处理和应答。</p>

<p><code>python
http_server = httpserver.HTTPServer(handle_request)
http_server = httpserver.HTTPServer(application)
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tornado源码分析4]]></title>
    <link href="http://amyangfei.me/2013/02/05/tornado-source-analysis-4/"/>
    <updated>2013-02-05T00:00:00+08:00</updated>
    <id>http://amyangfei.me/2013/02/05/tornado-source-analysis-4</id>
    <content type="html"><![CDATA[<p>IOStream对socket读写进行了封装，分别提供读、写缓冲区实现对socket的异步读写。当socket被accept之后HTTPServer的_handle_connection会被回调并初始化IOStream对象，进一步通过IOStream提供的功能接口完成socket的读写。文章接下来将关注IOStream实现读写的细节。</p>

<h3>IOStream的初始化</h3>

<p>IOStream初始化过程中主要完成以下操作：</p>

<ol>
<li>绑定对应的socket</li>
<li>绑定ioloop</li>
<li>创建读缓冲区_read_buffer，一个python deque容器</li>
<li>创建写缓冲区_write_buffer，同样也是一个python deque容器</li>
</ol>


<!-- more -->


<h3>IOStream提供的主要功能接口</h3>

<p>主要的读写接口包括以下四个：</p>

<table width="100%">
    <tbody>
        <tr>
            <td>
                class IOStream(object):
            </td>
        </tr>
        <tr>
            <td>&nbsp;&nbsp;&nbsp;&nbsp;def read_until(self, delimiter, callback):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def read_bytes(self, num_bytes, callback, streaming_callback=None):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def read_until_regex(self, regex, callback):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def read_until_close(self, callback, streaming_callback=None):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def write(self, data, callback=None):
            </td>
        </tr>
    </tbody>
</table>


<ul>
<li>read_until和read_bytes是最常用的读接口，它们工作的过程都是先注册读事件结束时调用的回调函数，然后调用_try_inline_read方法。_try_inline_read首先尝试_read_from_buffer，即从上一次的读缓冲区中取数据，如果有数据直接调用 self._run_callback(callback, self._consume(data_length)) 执行回调函数，_consume消耗掉了_read_buffer中的数据；否则即_read_buffer之前没有未读数据，先通过_read_to_buffer将数据从socket读入_read_buffer，然后再执行_read_from_buffer操作。read_until和read_bytes的区别在于_read_from_buffer过程中截取数据的方法不同，read_until读取到delimiter终止，而read_bytes则读取num_bytes个字节终止。执行过程如下图所示：</li>
</ul>


<p><img src="http://amyangfei.me/images/post/20130205iostream_read.png" style="margin-left:22px;"/></p>

<ul>
<li><p>read_until_regex相当于delimiter为某一正则表达式的read_until。</p></li>
<li><p>read_until_close主要用于IOStream流关闭前后的读取：如果调用read_until_close时stream已经关闭，那么将会_consume掉_read_buffer中的所有数据；否则_read_until_close标志位设为True，注册_streaming_callback回调函数，调用_add_io_state添加io_loop.READ状态。</p></li>
<li><p>write首先将data按照数据块大小WRITE_BUFFER_CHUNK_SIZE分块写入<em>write_buffer，然后调用</em>handle_write向socket发送数据。</p></li>
</ul>


<h3>其他内部功能接口</h3>

<ul>
<li><p>def _handle_events(self, fd, events): 通常为IOLoop对象add_handler方法传入的回调函数，由IOLoop的事件机制来进行调度。</p></li>
<li><p>def _add_io_state(self, state): 为IOLoop对象的handler注册IOLoop.READ或IOLoop.WRITE状态，handler为IOStream对象的_handle_events方法。</p></li>
<li><p>def _consume(self, loc): 合并读缓冲区loc个字节，从读缓冲区删除并返回这些数据</p></li>
</ul>


<h3>参考</h3>

<p><a href="http://kenby.iteye.com/blog/1159621" target="_blank">Tornado源码分析之http服务器篇</a>， <a href="http://www.cnblogs.com/Bozh/archive/2012/07/22/2603976.html" target="_blank">tornado源码分析系列</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tornado源码分析3]]></title>
    <link href="http://amyangfei.me/2013/02/03/tornado-source-analysis-3/"/>
    <updated>2013-02-03T00:00:00+08:00</updated>
    <id>http://amyangfei.me/2013/02/03/tornado-source-analysis-3</id>
    <content type="html"><![CDATA[<p>注：在分割线之前是基于 Tornado2.4 的分析。在Tornado3.0+以后IOLoop发生了一些改动，分割线之后有相应的介绍。</p>

<p>IOLoop是基于epoll实现的底层网络I/O的核心调度模块，用于处理socket相关的连接、响应、异步读写等网络事件。每个Tornado进程都会初始化一个全局唯一的IOLoop实例，在IOLoop中通过静态方法instance()进行封装，获取IOLoop实例直接调用此方法即可。</p>

<p>``` python
@staticmethod
def instance():</p>

<pre><code>"""
class MyClass(object):
    def __init__(self, io_loop=None):
        self.io_loop = io_loop or IOLoop.instance()
"""
if not hasattr(IOLoop, "_instance"):
    with IOLoop._instance_lock:
        if not hasattr(IOLoop, "_instance"):
            # New instance after double check
            IOLoop._instance = IOLoop()
return IOLoop._instance
</code></pre>

<p>```</p>

<!-- more -->


<p>在上一篇文章中已经分析Tornado服务器启动时会创建监听socket，并将socket的file descriptor注册到IOLoop实例中，IOLoop添加对socket的IOLoop.READ事件监听并传入回调处理函数。当某个socket通过accept接受连接请求后调用注册的回调函数进行读写。接下来主要分析IOLoop对epoll的封装和I/O调度具体实现。</p>

<p><a href="http://www.kernel.org/doc/man-pages/online/pages/man4/epoll.4.html" target="_blank">epoll</a>是Linux内核中实现的一种可扩展的I/O事件通知机制，是对POISX系统中<a href="http://www.kernel.org/doc/man-pages/online/pages/man2/select.2.html" target="_blank"> select(2) </a> 和<a href="http://www.kernel.org/doc/man-pages/online/pages/man2/poll.2.html" target="_blank"> poll(2) </a>的替代，具有更高的性能和扩展性，FreeBSD中类似的实现是kqueue。Tornado中基于Python C扩展实现的的epoll模块(或kqueue)对epoll(kqueue)的使用进行了封装，使得IOLoop对象可以通过相应的事件处理机制对I/O进行调度。</p>

<p>IOLoop模块对网络事件类型的封装与epoll一致，分为READ，WRITE， ERROR三类，具体如下所示。</p>

<p><code>python
READ = _EPOLLIN
WRITE = _EPOLLOUT
ERROR = _EPOLLERR | _EPOLLHUP
</code></p>

<h3>IOLoop的初始化</h3>

<p>初始化过程中选择epoll的实现方式，Linux平台为epoll，BSD平台为kqueue，其他平台如果安装有C模块扩展的epoll则使用tornado对epoll的封装，否则退化为select。</p>

<p>``` python
def <strong>init</strong>(self, impl=None):</p>

<pre><code>self._impl = impl or _poll()
#省略部分代码
self._waker = Waker()
self.add_handler(self._waker.fileno(),
                 lambda fd, events: self._waker.consume(),
                 self.READ)
</code></pre>

<p>def add_handler(self, fd, handler, events):</p>

<pre><code>"""Registers the given handler to receive the given events for fd."""
self._handlers[fd] = stack_context.wrap(handler)
self._impl.register(fd, events | self.ERROR)
</code></pre>

<p>```</p>

<p>在IOLoop初始化的过程中创建了一个Waker对象，将Waker对象fd的读端注册到事件循环中并设定相应的回调函数（这样做的好处是当事件循环阻塞而没有响应描述符出现，需要在最大timeout时间之前返回，就可以向这个管道发送一个字符）。Waker的使用：一种是在其他线程向IOLoop添加callback时使用，唤醒IOLoop同时会将控制权转移给IOLoop线程并完成特定请求。唤醒的方法向管道中写入一个字符'x'。另外，在IOLoop的stop函数中会调用self._waker.wake()，通过向管道写入'x'停止事件循环。</p>

<p>add_handler函数使用了stack_context提供的wrap方法。wrap返回了一个可以直接调用的对象并且保存了传入之前的堆栈信息，在执行时可以恢复，这样就保证了函数的异步调用时具有正确的运行环境。</p>

<h3>IOLoop的start方法</h3>

<p>IOLoop的核心调度集中在start方法中，IOLoop实例对象调用start后开始epoll事件循环机制，该方法会一直运行直到IOLoop对象调用stop函数、当前所有事件循环完成。start方法中主要分三个部分：一个部分是对超时的相关处理；一部分是epoll事件通知阻塞、接收；一部分是对epoll返回I/O事件的处理。</p>

<ul>
<li><p>为防止IO event starvation，将回调函数延迟到下一轮事件循环中执行。</p></li>
<li><p>超时的处理
heapq维护一个最小堆，记录每个回调函数的超时时间（deadline）。每次取出deadline最早的回调函数，如果callback标志位为True并且已经超时，通过_run_callback调用函数；如果没有超时需要重新设定poll_timeout的值。</p></li>
<li><p>通过self._impl.poll(poll_timeout)进行事件阻塞，当有事件通知或超时时poll返回特定的event_pairs。</p></li>
<li><p>epoll返回通知事件后将新事件加入待处理队列，将就绪事件逐个弹出，通过stack_context.wrap(handler)保存的可执行对象调用事件处理。</p></li>
</ul>


<p>``` python
while True:</p>

<pre><code>poll_timeout = 3600.0

with self._callback_lock:
    callbacks = self._callbacks
    self._callbacks = []
for callback in callbacks:
    self._run_callback(callback)

# 超时处理
if self._timeouts:
    now = time.time()
    while self._timeouts:
        if self._timeouts[0].callback is None:
            # the timeout was cancelled
            heapq.heappop(self._timeouts)
        elif self._timeouts[0].deadline &lt;= now:
            timeout = heapq.heappop(self._timeouts)
            self._run_callback(timeout.callback)
        else:
            seconds = self._timeouts[0].deadline - now
            poll_timeout = min(seconds, poll_timeout)
            break

if self._callbacks:
    # If any callbacks or timeouts called add_callback,
    # we don't want to wait in poll() before we run them.
    poll_timeout = 0.0

if not self._running:
    break

if self._blocking_signal_threshold is not None:
    # clear alarm so it doesn't fire while poll is waiting for events.
    signal.setitimer(signal.ITIMER_REAL, 0, 0)

# epoll阻塞，当有事件通知或超时返回event_pairs
try:
    event_pairs = self._impl.poll(poll_timeout)
except Exception, e:
    # 异常处理，省略

# 对epoll返回event_pairs事件的处理
self._events.update(event_pairs)
while self._events:
    fd, events = self._events.popitem()
    try:
        self._handlers[fd](fd, events)
    except Exception e:
        # 异常处理，省略
</code></pre>

<p>```</p>

<p>至此IOLoop模块的分析基本完成。下一篇文章将会继续分析IOStream模块。</p>

<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;我是分割线&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</p>

<p>补充于2013年4月30日，介绍Tornado3.0以后IOLoop模块的一些改动。</p>

<p>1. IOLoop成为util.Configurable的子类，IOLoop 中绝大多数成员方法都作为抽象接口，具体实现由派生类 PollIOLoop 完成。IOLoop实现了 Configurable 中的 configurable_base 和 configurable_default 这两个抽象接口，用于初始化过程中获取类类型和类的实现方法（即 IOLoop 中 poller 的实现方式）。在Tornado3.0+ 中针对不同平台，单独出 poller 相应的实现，EPollIOLoop、KQueueIOLoop、SelectIOLoop 均继承于 PollIOLoop。下边的代码是 configurable_default 方法根据平台选择相应的 epoll 实现。初始化 IOLoop 的过程中会自动根据平台选择合适的 poller 的实现方法。</p>

<p>``` python
@classmethod
def configurable_default(cls):</p>

<pre><code>if hasattr(select, "epoll"):
    from tornado.platform.epoll import EPollIOLoop
    return EPollIOLoop
if hasattr(select, "kqueue"):
    # Python 2.6+ on BSD or Mac
    from tornado.platform.kqueue import KQueueIOLoop
    return KQueueIOLoop
from tornado.platform.select import SelectIOLoop
return SelectIOLoop
</code></pre>

<p>```</p>

<p>2. 其他有很多细节上的改动，详细可参见官方文档<a href="http://www.tornadoweb.org/en/stable/releases/v3.0.0.html#tornado-ioloop" target="_blank">What’s new in Tornado 3.0</a></p>

<h3>参考</h3>

<p><a href="http://kenby.iteye.com/blog/1159621" target="_blank">Tornado源码分析之http服务器篇</a>， <a href="http://www.cnblogs.com/Bozh/archive/2012/07/22/2603976.html" target="_blank">tornado源码分析系列</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tornado源码分析2]]></title>
    <link href="http://amyangfei.me/2013/01/29/tornado-source-analysis-2/"/>
    <updated>2013-01-29T00:00:00+08:00</updated>
    <id>http://amyangfei.me/2013/01/29/tornado-source-analysis-2</id>
    <content type="html"><![CDATA[<p>httpserver.py中给出了一个简单的http服务器的demo，代码如下所示：</p>

<p>``` python
from tornado import httpserver
from tornado import ioloop</p>

<p>def handle_request(request):
   message = &ldquo;You requested %s\n&rdquo; % request.uri
   request.write(&ldquo;HTTP/1.1 200 OK\r\nContent-Length: %d\r\n\r\n%s&rdquo; % (</p>

<pre><code>             len(message), message))
</code></pre>

<p>   request.finish()</p>

<p>http_server = httpserver.HTTPServer(handle_request)
http_server.bind(8888)
http_server.start()
ioloop.IOLoop.instance().start()
```</p>

<p>该http服务器主要使用到IOLoop, IOStream, HTTPServer, HTTPConnection几大模块，分别在代码ioloop.py, iostream.py, httpserver.py中实现。工作的流程如下图所示：</p>

<!-- more -->


<p><img src="http://amyangfei.me/images/post/20130128tornado-httpserver.png" style="width:610px;"/></p>

<p>服务器的工作流程：首先按照socket->bind->listen顺序创建listen socket监听客户端，并将每个listen socket的fd注册到IOLoop的单例实例中；当listen socket可读时回调_handle_events处理客户端请求；在与客户端通信的过程中使用IOStream封装了读、写缓冲区，实现与客户端的异步读写。</p>

<h3>HTTPServer分析</h3>

<p>HTTPServer在httpserver.py中实现，继承自TCPServer（netutil.py中实现），是一个无阻塞、单线程HTTP服务器。支持HTTP/1.1协议keep-alive连接，但不支持chunked encoding。服务器支持'X-Real-IP'和'X-Scheme'头以及SSL传输，支持多进程为prefork模式实现。在源代码的注释中对以上描述比较详细的说明，这里就不再细说。</p>

<p>HTTPServer和TCPServer的类结构</p>

<table width="100%">
    <tbody>
        <tr>
            <td>
                class HTTPServer(TCPServer):
            </td>
        </tr>
        <tr>
            <td>&nbsp;&nbsp;&nbsp;&nbsp;def __init__(self, request_callback, no_keep_alive=False, io_loop=None,
                 xheaders=False, ssl_options=None, **kwargs):
                <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def handle_stream(self, stream, address):
            </td>
        </tr>
    </tbody>
</table>




<table width="100%">
    <tbody>
        <tr>
            <td>
                class TCPServer(object):
            </td>
        </tr>
        <tr>
            <td>&nbsp;&nbsp;&nbsp;&nbsp;def __init__(self, io_loop=None, ssl_options=None):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def listen(self, port, address=""):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def add_sockets(self, sockets):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128):   
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def start(self, num_processes=1):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def stop(self):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def handle_stream(self, stream, address):
            <br>
                &nbsp;&nbsp;&nbsp;&nbsp;def _handle_connection(self, connection, address):
            </td>
        </tr>
    </tbody>
</table>


<p>文章开始部分创建HTTPServer的过程：首先需要定义处理request的回调函数，在tornado中通常使用tornado.web.Application封装。然后构造HTTPServer实例，注册回调函数。接下来监听端口，启动服务器。最后启动IOLoop。</p>

<p>``` python</p>

<p>def listen(self, port, address=&ldquo;&rdquo;):</p>

<pre><code>sockets = bind_sockets(port, address=address)
self.add_sockets(sockets)
</code></pre>

<p>def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=128):</p>

<pre><code># 省略sockets创建，address，flags处理部分代码
for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM,
                              0, flags)):
    af, socktype, proto, canonname, sockaddr = res
    # 创建socket
    sock = socket.socket(af, socktype, proto)
    # 设置socket属性，代码省略

    sock.bind(sockaddr)
    sock.listen(backlog)
    sockets.append(sock)
return sockets
</code></pre>

<p>def add_sockets(self, sockets):</p>

<pre><code>if self.io_loop is None:
    self.io_loop = IOLoop.instance()

for sock in sockets:
    self._sockets[sock.fileno()] = sock
    add_accept_handler(sock, self._handle_connection,
                       io_loop=self.io_loop)
</code></pre>

<p>def add_accept_handler(sock, callback, io_loop=None):</p>

<pre><code>if io_loop is None:
    io_loop = IOLoop.instance()

def accept_handler(fd, events):
    while True:
        try:
            connection, address = sock.accept()
        except socket.error, e:
            if e.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):
                return
            raise
        # 当有连接被accepted时callback会被调用
        callback(connection, address)
io_loop.add_handler(sock.fileno(), accept_handler, IOLoop.READ)
</code></pre>

<p>def _handle_connection(self, connection, address):</p>

<pre><code># SSL部分省略
try:
    stream = IOStream(connection, io_loop=self.io_loop)
    self.handle_stream(stream, address)
except Exception:
    logging.error("Error in connection callback", exc_info=True)
</code></pre>

<p>```</p>

<p>这里分析HTTPServer通过listen函数启动监听，这种方法是单进程模式。另外可以通过先后调用bind和start(num_processes=1)函数启动监听同时创建多进程服务器实例，后文有关于此的详细描述。</p>

<p>bind_sockets在启动监听端口过程中调用，getaddrinfo返回服务器的所有网卡信息, 每块网卡上都要创建监听客户端的请求并返回创建的sockets。创建socket过程中绑定地址和端口，同时设置了fcntl.FD_CLOEXEC（创建子进程时关闭打开的socket）和socket.SO_REUSEADDR（保证某一socket关闭后立即释放端口，实现端口复用）标志位。sock.listen(backlog=128)默认设定等待被处理的连接最大个数为128。</p>

<p>返回的每一个socket都加入到IOLoop中同时添加回调函数_handle_connection，IOLoop添加对相应socket的IOLoop.READ事件监听。_handle_connection在接受客户端的连接处理结束之后会被调用，调用时传入连接和ioloop对象初始化IOStream对象，用于对客户端的异步读写；然后调用handle_stream，传入创建的IOStream对象初始化一个HTTPConnection对象，HTTPConnection封装了IOStream的一些操作，用于处理HTTPRequest并返回。至此HTTP Server的创建、启动、注册回调函数的过程分析结束。</p>

<h3>HTTPConnection分析</h3>

<p>该类用于处理http请求。在HTTPConnection初始化时对self.request_callback赋值为一个可调用的对象（该对象用于对http请求的具体处理和应答）。该类首先读取http请求中header的结束符b(&ldquo;\r\n\r\n&rdquo;)，然后回调self._on_headers函数。request_callback的相关实现在以后的系列中有详细介绍。</p>

<p>``` python
def <strong>init</strong>(self, stream, address, request_callback, no_keep_alive=False,</p>

<pre><code>             xheaders=False):
self.request_callback = request_callback
# some configuration code
self._header_callback = stack_context.wrap(self._on_headers)
self.stream.read_until(b("\r\n\r\n"), self._header_callback)
</code></pre>

<p>def _on_headers(self, data):</p>

<pre><code># some codes
self.request_callback(self._request)
</code></pre>

<p>```</p>

<h3>多进程HTTPServer</h3>

<p>Tornado的HTTPServer是单进程单线程模式，同时提供了创建多进程服务器的接口，具体实现是在主进程启动HTTPServer时通过process.fork_processes(num_processes)产生新的服务器子进程，所有进程之间共享端口。fork_process的方法在process.py中实现，十分简洁。<a href="http://fjctlzy.diandian.com/post/2012-08-04/40031899614" target="_blank">从开源代码学习Python之tornado的多进程</a> 对fork_process有详细的分析。</p>

<p>FriendFeed使用nginx提供负载均衡、反向代理服务并作为静态文件服务器，在后端服务器上可以部署多个Tornado实例。<a href="http://www.v2ex.com/t/17505" target="_blank">v2ex:Tornado 项目都是如何部署</a> 里讨论的方案是通过Supervisor控制Tornado app，然后再通过nginx对Tornado的输出进行反向代理。<a href="https://idndx.com/2011/10/18/ways-to-deploy-tornado-under-production-environment-using-supervisor/" target="_blank">Tornado + Supervisor 在生产环境下的部署方法</a> 这篇文章也有相似的讨论。</p>

<h3>参考</h3>

<p><a href="http://kenby.iteye.com/blog/1159621" target="_blank">Tornado源码分析之http服务器篇</a>， <a href="http://www.cnblogs.com/Bozh/archive/2012/07/24/2606765.html" target="_blank">tornado源码分析系列</a>， <a href="http://golubenco.org/2009/09/19/understanding-the-code-inside-tornado-the-asynchronous-web-server-powering-friendfeed/" target="_blank">Understanding the code inside Tornado, the asynchronous web server</a></p>
]]></content>
  </entry>
  
</feed>
